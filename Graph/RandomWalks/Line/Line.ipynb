{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from decimal import *\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from vose_sampler import VoseAlias\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn\n",
    "import torch.optim\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = 0.75\n",
    "batchsize=5\n",
    "epochs=100\n",
    "negativepower = 0.75\n",
    "negsamplesize = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.edge_index.T.numpy())\n",
    "weight = torch.randint(1,100,( data.edge_index.shape[1] , ) )\n",
    "df['weight'] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgedistdict = collections.defaultdict(int)\n",
    "nodedistdict = collections.defaultdict(int)\n",
    "\n",
    "weightsdict = collections.defaultdict(int)\n",
    "nodedegrees = collections.defaultdict(int)\n",
    "\n",
    "weightsum = 0\n",
    "negprobsum = 0\n",
    "\n",
    "nlines = 0\n",
    "maxindex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.values:\n",
    "    node1 = row[0]\n",
    "    node2 = row[1]\n",
    "    weight = row[2]\n",
    "    \n",
    "    edgedistdict[tuple([node1, node2])] = weight # edge의 weight기록\n",
    "    nodedistdict[node1] += weight # node에서 나가는 weight를 더해준다 -> directed\n",
    "    \n",
    "    weightsdict[tuple([node1, node2])] = weight # edge의 weight 기록\n",
    "    nodedegrees[node1] += weight # node에서 나가는 weight를 더해준다 -> directed\n",
    "    \n",
    "    weightsum += weight # W\n",
    "    negprobsum += np.power(weight, power) # negative sampling시 3/4 term\n",
    "    \n",
    "    # maxindex기록(왜 필요?)\n",
    "    if node1 > maxindex:\n",
    "        maxindex = node1\n",
    "    elif node2 > maxindex:\n",
    "        maxindex = node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, outdegree in nodedistdict.items(): # negative sampling term으로 변환\n",
    "    nodedistdict[node] = np.power(outdegree, power) / negprobsum \n",
    "    \n",
    "for edge, weight in edgedistdict.items(): # wij/W로 변환\n",
    "    edgedistdict[edge] = weight / weightsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VoseAlias Sampling\n",
    "edgesampler = VoseAlias(edgedistdict)\n",
    "nodesampler = VoseAlias(nodedistdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchrange = int(len(edgedistdict)/batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negSampleBatch(sourcenode, targetnode, negsamplesize, nodedegrees, nodesampler, t=10e-3):\n",
    "    \"\"\"\n",
    "    For generating negative samples.\n",
    "    \"\"\"\n",
    "    negsamples = 0\n",
    "    while negsamples < negsamplesize:\n",
    "        samplednode = nodesampler.sample_n(1)\n",
    "        if (samplednode == sourcenode) or (samplednode == targetnode):\n",
    "            continue\n",
    "        else:\n",
    "            negsamples += 1\n",
    "            yield samplednode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeData(samplededges, negsamplesize, nodedegrees, nodesampler):\n",
    "    for e in samplededges:\n",
    "        sourcenode, targetnode = e[0], e[1]\n",
    "        negnodes = []\n",
    "        for negsample in negSampleBatch(sourcenode, targetnode, negsamplesize, nodedegrees, nodesampler, t=10e-3):\n",
    "            for node in negsample:\n",
    "                negnodes.append(node)\n",
    "        yield [e[0], e[1]] + negnodes\n",
    "# 0, 1에는 source, target이고 2~ 는 negative sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line(nn.Module):\n",
    "    def __init__(self, size, embed_dim=128, order=2):\n",
    "        super(Line, self).__init__()\n",
    "\n",
    "        assert order in [1, 2], print(\"Order should either be int(1) or int(2)\")\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.order = order\n",
    "        self.nodes_embeddings = nn.Embedding(size, embed_dim)\n",
    "\n",
    "        if order == 2:\n",
    "            self.contextnodes_embeddings = nn.Embedding(size, embed_dim)\n",
    "            # Initialization\n",
    "            self.contextnodes_embeddings.weight.data = self.contextnodes_embeddings.weight.data.uniform_(\n",
    "                -.5, .5) / embed_dim\n",
    "\n",
    "        # Initialization\n",
    "        self.nodes_embeddings.weight.data = self.nodes_embeddings.weight.data.uniform_(\n",
    "            -.5, .5) / embed_dim\n",
    "\n",
    "    def forward(self, v_i, v_j, negsamples):\n",
    "\n",
    "        v_i = self.nodes_embeddings(v_i)\n",
    "\n",
    "        if self.order == 2:\n",
    "            v_j = self.contextnodes_embeddings(v_j)\n",
    "            negativenodes = -self.contextnodes_embeddings(negsamples)\n",
    "\n",
    "        else:\n",
    "            v_j = self.nodes_embeddings(v_j)\n",
    "            negativenodes = -self.nodes_embeddings(negsamples)\n",
    "\n",
    "        mulpositivebatch = torch.mul(v_i, v_j)\n",
    "        positivebatch = F.logsigmoid(torch.sum(mulpositivebatch, dim=1))\n",
    "\n",
    "        mulnegativebatch = torch.mul(v_i.view(len(v_i), 1, self.embed_dim), negativenodes)\n",
    "        negativebatch = torch.sum(\n",
    "            F.logsigmoid(\n",
    "                torch.sum(mulnegativebatch, dim=2)\n",
    "            ),\n",
    "            dim=1)\n",
    "        loss = positivebatch + negativebatch\n",
    "        return -torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Line(\n",
       "  (nodes_embeddings): Embedding(2708, 128)\n",
       "  (contextnodes_embeddings): Embedding(2708, 128)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Line(size=maxindex+1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossdata = {\"it\": [], \"loss\": []}\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss:0.37782058119773865\n",
      "epoch:20, loss:0.19048920273780823\n",
      "epoch:30, loss:0.17091511189937592\n",
      "epoch:40, loss:0.15600639581680298\n",
      "epoch:50, loss:0.16630582511425018\n",
      "epoch:60, loss:0.16645987331867218\n",
      "epoch:70, loss:0.15748505294322968\n",
      "epoch:80, loss:0.1596524566411972\n",
      "epoch:90, loss:0.17914359271526337\n",
      "epoch:100, loss:0.1658223420381546\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for b in range(batchrange): # 왜 이만큼 반복해야하지?\n",
    "        \n",
    "        # forward\n",
    "        samplededges = edgesampler.sample_n(batchsize) # batchsize만큼 edge를 sampling\n",
    "        batch = list(makeData(samplededges, negsamplesize, nodedegrees, nodesampler))\n",
    "        batch = torch.LongTensor(batch)\n",
    "        v_i = batch[:, 0]\n",
    "        v_j = batch[:, 1]\n",
    "        negsamples = batch[:, 2:]\n",
    "        \n",
    "        # initialize\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # loss\n",
    "        loss = model(v_i.to(device), v_j.to(device), negsamples.to(device))\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        opt.step()\n",
    "\n",
    "        # writing\n",
    "        lossdata[\"loss\"].append(loss.item())\n",
    "        lossdata[\"it\"].append(it)\n",
    "        it += 1\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    train_loss = total_loss / batchrange\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(\"epoch:{}, loss:{}\".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study2",
   "language": "python",
   "name": "study2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
