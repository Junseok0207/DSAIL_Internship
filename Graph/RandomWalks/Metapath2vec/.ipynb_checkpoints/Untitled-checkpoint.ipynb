{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from torch_geometric.datasets import AMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a78e8ecd4164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AMiner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data','AMiner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/1bnz8r7mofx0osf/net_aminer.zip?dl=1\n",
      "Extracting /tmp/Aminer/net_aminer.zip?dl=1\n",
      "Downloading https://www.dropbox.com/s/nkocx16rpl4ydde/label.zip?dl=1\n",
      "Extracting /tmp/Aminer/raw/label.zip?dl=1\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = AMiner(root='/tmp/Aminer')#, name='Aminer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "metapath = [\n",
    "    ('author', 'wrote', 'paper'),\n",
    "    ('paper', 'published in', 'venue'),\n",
    "    ('venue', 'published', 'paper'),\n",
    "    ('paper', 'written by', 'author'),\n",
    "]\n",
    "embedding_dim = 128\n",
    "walk_length = 50\n",
    "context_size=7\n",
    "walks_per_node=5\n",
    "num_negative_samples=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "  edge_index_dict={\n",
       "    ('paper', 'written by', 'author')=[2, 9323605],\n",
       "    ('author', 'wrote', 'paper')=[2, 9323605],\n",
       "    ('paper', 'published in', 'venue')=[2, 3194405],\n",
       "    ('venue', 'published', 'paper')=[2, 3194405]\n",
       "  },\n",
       "  num_nodes_dict={\n",
       "    paper=3194405,\n",
       "    author=1693531,\n",
       "    venue=3883\n",
       "  },\n",
       "  y_dict={\n",
       "    author=[246678],\n",
       "    venue=[134]\n",
       "  },\n",
       "  y_index_dict={\n",
       "    author=[246678],\n",
       "    venue=[134]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dict = {}\n",
    "for keys, edge_index in data.edge_index_dict.items():\n",
    "    sizes = (data.num_nodes_dict[keys[0]], data.num_nodes_dict[keys[-1]])\n",
    "    row, col = edge_index\n",
    "    adj = SparseTensor(row=row, col=col, sparse_sizes=sizes)\n",
    "    adj_dict[keys] = adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('paper',\n",
       "  'written by',\n",
       "  'author'): SparseTensor(row=tensor([      0,       1,       2,  ..., 3194404, 3194404, 3194404]),\n",
       "              col=tensor([     0,      1,      2,  ...,   4393,  21681, 317436]),\n",
       "              size=(3194405, 1693531), nnz=9323605, density=0.00%),\n",
       " ('author',\n",
       "  'wrote',\n",
       "  'paper'): SparseTensor(row=tensor([      0,       0,       0,  ..., 1693528, 1693529, 1693530]),\n",
       "              col=tensor([      0,   45988,  124807,  ..., 3194371, 3194387, 3194389]),\n",
       "              size=(1693531, 3194405), nnz=9323605, density=0.00%),\n",
       " ('paper',\n",
       "  'published in',\n",
       "  'venue'): SparseTensor(row=tensor([      0,       1,       2,  ..., 3194402, 3194403, 3194404]),\n",
       "              col=tensor([2190, 2190, 2190,  ..., 3148, 3148, 3148]),\n",
       "              size=(3194405, 3883), nnz=3194405, density=0.03%),\n",
       " ('venue',\n",
       "  'published',\n",
       "  'paper'): SparseTensor(row=tensor([   0,    0,    0,  ..., 3882, 3882, 3882]),\n",
       "              col=tensor([2203069, 2203070, 2203071,  ...,  952391,  952392,  952393]),\n",
       "              size=(3883, 3194405), nnz=3194405, density=0.03%)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author', 'paper', 'venue']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = set(x[0] for x in metapath) | set(x[-1] for x in metapath)\n",
    "sorted(list(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "start, end = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in types:\n",
    "    start[key] = count\n",
    "    count += data.num_nodes_dict[key]\n",
    "    end[key] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': 0, 'author': 3194405, 'venue': 4887936}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': 3194405, 'author': 4887936, 'venue': 4891819}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = [start[metapath[0][0]]]\n",
    "offset += [start[keys[-1]] for keys in metapath] * int((walk_length / len(metapath)) + 1)\n",
    "offset = offset[:walk_length + 1]\n",
    "assert len(offset) == walk_length + 1\n",
    "offset = torch.tensor(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3194405,       0, 4887936,       0, 3194405,       0, 4887936,       0,\n",
       "        3194405,       0, 4887936,       0, 3194405,       0, 4887936,       0,\n",
       "        3194405,       0, 4887936,       0, 3194405,       0, 4887936,       0,\n",
       "        3194405,       0, 4887936,       0, 3194405,       0, 4887936,       0,\n",
       "        3194405,       0, 4887936,       0, 3194405,       0, 4887936,       0,\n",
       "        3194405,       0, 4887936,       0, 3194405,       0, 4887936,       0,\n",
       "        3194405,       0, 4887936])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(count, embedding_dim, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4891819"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(self, **kwargs):\n",
    "    return DataLoader(range(data.num_nodes_dict[metapath[0][0]]),\n",
    "                     collate_fn = sample, **kwargs\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self, batch):\n",
    "    if not isinstance(batch, torch.Tensor):\n",
    "        batch = torch.tensor(batch)\n",
    "    return pos_sample(batch), neg_sample(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_sample(self, batch):\n",
    "    # device = self.embedding.weight.device\n",
    "\n",
    "    batch = batch.repeat(walks_per_node)\n",
    "\n",
    "    rws = [batch]\n",
    "    for i in range(walk_length):\n",
    "        keys = metapath[i % len(metapath)]\n",
    "        adj = adj_dict[keys]\n",
    "        batch = adj.sample(num_neighbors=1, subset=batch).squeeze()\n",
    "        rws.append(batch)\n",
    "\n",
    "    rw = torch.stack(rws, dim=-1)\n",
    "    rw.add_(offset.view(1, -1))\n",
    "\n",
    "    walks = []\n",
    "    num_walks_per_rw = 1 + walk_length + 1 - context_size\n",
    "    for j in range(num_walks_per_rw):\n",
    "        walks.append(rw[:, j:j + context_size])\n",
    "    return torch.cat(walks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sample(self, batch):\n",
    "    batch = batch.repeat(walks_per_node * num_negative_samples)\n",
    "\n",
    "    rws = [batch]\n",
    "    for i in range(walk_length):\n",
    "        keys = metapath[i % len(metapath)]\n",
    "        batch = torch.randint(0, num_nodes_dict[keys[-1]],\n",
    "                              (batch.size(0), ), dtype=torch.long)\n",
    "        rws.append(batch)\n",
    "\n",
    "    rw = torch.stack(rws, dim=-1)\n",
    "    rw.add_(offset.view(1, -1))\n",
    "\n",
    "    walks = []\n",
    "    num_walks_per_rw = 1 + walk_length + 1 - context_size\n",
    "    for j in range(num_walks_per_rw):\n",
    "        walks.append(rw[:, j:j + context_size])\n",
    "    return torch.cat(walks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(range(data.num_nodes_dict[metapath[0][0]]), \n",
    "                   collate_fn = sample,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    num_workers=12\n",
    "                   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/junseok/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/junseok/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\nTypeError: sample() missing 1 required positional argument: 'batch'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-41abc52d198e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/junseok/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/junseok/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\nTypeError: sample() missing 1 required positional argument: 'batch'\n"
     ]
    }
   ],
   "source": [
    "for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "    print(pos_rw)\n",
    "    print(neg_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaPath2Vec(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, edge_index_dict, embedding_dim, metapath, walk_length,\n",
    "                 context_size, walks_per_node=1, num_negative_samples=1,\n",
    "                 num_nodes_dict=None, sparse=False):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "\n",
    "        if num_nodes_dict is None:\n",
    "            num_nodes_dict = {}\n",
    "            for keys, edge_index in edge_index_dict.items():\n",
    "                key = keys[0]\n",
    "                N = int(edge_index[0].max() + 1)\n",
    "                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))\n",
    "\n",
    "                key = keys[-1]\n",
    "                N = int(edge_index[1].max() + 1)\n",
    "                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))\n",
    "\n",
    "        adj_dict = {}\n",
    "        for keys, edge_index in edge_index_dict.items():\n",
    "            sizes = (num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]])\n",
    "            row, col = edge_index\n",
    "            adj = SparseTensor(row=row, col=col, sparse_sizes=sizes)\n",
    "            adj = adj.to('cpu')\n",
    "            adj_dict[keys] = adj\n",
    "\n",
    "        assert metapath[0][0] == metapath[-1][-1]\n",
    "        assert walk_length >= context_size\n",
    "\n",
    "        self.adj_dict = adj_dict\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.metapath = metapath\n",
    "        self.walk_length = walk_length\n",
    "        self.context_size = context_size\n",
    "        self.walks_per_node = walks_per_node\n",
    "        self.num_negative_samples = num_negative_samples\n",
    "        self.num_nodes_dict = num_nodes_dict\n",
    "\n",
    "        types = set([x[0] for x in metapath]) | set([x[-1] for x in metapath])\n",
    "        types = sorted(list(types))\n",
    "\n",
    "        count = 0\n",
    "        self.start, self.end = {}, {}\n",
    "        for key in types:\n",
    "            self.start[key] = count\n",
    "            count += num_nodes_dict[key]\n",
    "            self.end[key] = count\n",
    "\n",
    "        offset = [self.start[metapath[0][0]]]\n",
    "        offset += [self.start[keys[-1]] for keys in metapath\n",
    "                   ] * int((walk_length / len(metapath)) + 1)\n",
    "        offset = offset[:walk_length + 1]\n",
    "        assert len(offset) == walk_length + 1\n",
    "        self.offset = torch.tensor(offset)\n",
    "\n",
    "        self.embedding = Embedding(count, embedding_dim, sparse=sparse)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding.reset_parameters()\n",
    "\n",
    "    def forward(self, node_type, batch=None):\n",
    "        \"\"\"Returns the embeddings for the nodes in :obj:`subset` of type\n",
    "        :obj:`node_type`.\"\"\"\n",
    "        emb = self.embedding.weight[self.start[node_type]:self.end[node_type]]\n",
    "        return emb if batch is None else emb[batch]\n",
    "\n",
    "    def loader(self, **kwargs):\n",
    "        return DataLoader(range(self.num_nodes_dict[self.metapath[0][0]]),\n",
    "                          collate_fn=self.sample, **kwargs)\n",
    "\n",
    "    def pos_sample(self, batch):\n",
    "        # device = self.embedding.weight.device\n",
    "\n",
    "        batch = batch.repeat(self.walks_per_node)\n",
    "\n",
    "        rws = [batch]\n",
    "        for i in range(self.walk_length):\n",
    "            keys = self.metapath[i % len(self.metapath)]\n",
    "            adj = self.adj_dict[keys]\n",
    "            batch = adj.sample(num_neighbors=1, subset=batch).squeeze()\n",
    "            rws.append(batch)\n",
    "\n",
    "        rw = torch.stack(rws, dim=-1)\n",
    "        rw.add_(self.offset.view(1, -1))\n",
    "\n",
    "        walks = []\n",
    "        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size\n",
    "        for j in range(num_walks_per_rw):\n",
    "            walks.append(rw[:, j:j + self.context_size])\n",
    "        return torch.cat(walks, dim=0)\n",
    "\n",
    "    def neg_sample(self, batch):\n",
    "        batch = batch.repeat(self.walks_per_node * self.num_negative_samples)\n",
    "\n",
    "        rws = [batch]\n",
    "        for i in range(self.walk_length):\n",
    "            keys = self.metapath[i % len(self.metapath)]\n",
    "            batch = torch.randint(0, self.num_nodes_dict[keys[-1]],\n",
    "                                  (batch.size(0), ), dtype=torch.long)\n",
    "            rws.append(batch)\n",
    "\n",
    "        rw = torch.stack(rws, dim=-1)\n",
    "        rw.add_(self.offset.view(1, -1))\n",
    "\n",
    "        walks = []\n",
    "        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size\n",
    "        for j in range(num_walks_per_rw):\n",
    "            walks.append(rw[:, j:j + self.context_size])\n",
    "        return torch.cat(walks, dim=0)\n",
    "\n",
    "    def sample(self, batch):\n",
    "        if not isinstance(batch, torch.Tensor):\n",
    "            batch = torch.tensor(batch)\n",
    "        return self.pos_sample(batch), self.neg_sample(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
    "                         metapath=metapath, walk_length=50, context_size=7,\n",
    "                         walks_per_node=5, num_negative_samples=5,\n",
    "                         sparse=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaPath2Vec(\n",
       "  (embedding): Embedding(4891819, 128, sparse=True)\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = model.loader(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1693531"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes_dict[metapath[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n",
      "pos_rw\n",
      "torch.Size([28800, 7])\n",
      "neg_rw\n",
      "torch.Size([144000, 7])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-79adeb1f51dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pos_rw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"neg_rw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-219-f94f5909a0f8>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-219-f94f5909a0f8>\u001b[0m in \u001b[0;36mneg_sample\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_walks_per_rw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mwalks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "    print(\"pos_rw\")\n",
    "    print(pos_rw.shape)\n",
    "    print(\"neg_rw\")\n",
    "    print(neg_rw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study2",
   "language": "python",
   "name": "study2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
