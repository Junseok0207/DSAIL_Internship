{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from torch_geometric.datasets import AMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaPath2Vec(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        edge_index_dict(dict) :obj : (source_node_type, relation_type, target_node_type) tuples\n",
    "        \n",
    "        embedding_dim(int) \n",
    "        \n",
    "        metapath(list) : obj : (source_node_type, relation_type, target_node_type) tuples\n",
    "        \n",
    "        walk_length(int)\n",
    "        \n",
    "        context_size(int) \n",
    "        \n",
    "        walks_per_node(int, optional) : walk를 몇번 할지\n",
    "        \n",
    "        num_negative_samples(int, optional) : \n",
    "        \n",
    "        num_nodes_dict(dict, optional) : \n",
    "        \n",
    "        sparse (bool, optional) : \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, edge_index_dict, embedding_dim, metapath, walk_length,\n",
    "                context_size, walks_per_node=1, num_negative_samples=1,\n",
    "                 num_nodes_dict = None, sparse=False):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        \n",
    "        \n",
    "        # num_nodes_dict이 입력되지 않을 경우 생성\n",
    "        if num_nodes_dict is None:\n",
    "            num_nodes_dict = {}\n",
    "            for keys, edge_index in edge_index_dict.items():\n",
    "                key = keys[0]\n",
    "                N = int(edge_index[0].max() + 1)\n",
    "                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))\n",
    "                \n",
    "                key = keys[-1]\n",
    "                N = int(edge_index[1].max() + 1)\n",
    "                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))\n",
    "        \n",
    "        # Sparse Tensor로 변환(edge_index_dict -> adj_dict)\n",
    "        adj_dict = {}\n",
    "        for keys, edge_index in edge_index_dict.items():\n",
    "            sizes = (num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]])\n",
    "            row, col = edge_index\n",
    "            adj = SparseTensor(row=row, col=col, sparse_sizes=sizes)\n",
    "            adj = adj.to('cpu')\n",
    "            adj_dict[keys] = adj\n",
    "            \n",
    "        assert metapath[0][0] == metapath[-1][-1] # metapath는 대칭적이여야함\n",
    "        assert walk_length >= context_size\n",
    "        \n",
    "        self.adj_dict = adj_dict\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.metapath = metapath\n",
    "        self.walk_length = walk_length\n",
    "        self.context_size = context_size\n",
    "        self.walks_per_node = walks_per_node\n",
    "        self.num_negative_samples = num_negative_samples\n",
    "        self.num_nodes_dict = num_nodes_dict\n",
    "        \n",
    "        # metapath에 존재하는 모든 type\n",
    "        types = set(x[0] for x in metapath) | set(x[-1] for x in metapath)\n",
    "        types = sorted(list(type))\n",
    "        \n",
    "        # count : metapath안에 있는 type들의 전체 갯수\n",
    "        # start ~ end : 특정 type의 embedding의 위치 \n",
    "        count = 0\n",
    "        self.start, self.end = {}, {}\n",
    "        for key in types:\n",
    "            self.start[key] = count\n",
    "            count += num_nodes_dict[key]\n",
    "            self.end[key] = count\n",
    "        \n",
    "        \n",
    "        # offset : meta path의 각 스템에서 start지점을 표시 \n",
    "        offset = [self.start[metapath[0][0]]]\n",
    "        offset += [self.start[keys[-1]] for keys in metapath] * int((walk_length / len(metapath)) + 1)\n",
    "        offset = offset[:walk_length + 1]\n",
    "        assert len(offset) == walk_length + 1\n",
    "        self.offset = torch.tensor(offset)\n",
    "        \n",
    "        self.embedding = Embedding(count, embedding_dim, sparse=sparse)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "        # embedding parameter 초기화\n",
    "        def reset_parameters(self):\n",
    "            self.embedding.reset_parameters()\n",
    "        \n",
    "        # forward pass - nodetype을 주면 그 embedding값 출력\n",
    "        def forward(self, node_type, batch=None):\n",
    "            \"\"\"\n",
    "            Returns the embeddings for the nodes in :\n",
    "            obj:'node_type'\n",
    "            \"\"\"\n",
    "            emb = self.embedding.weight[self.start[node_type]:self.end[node_type]]\n",
    "            return emb if batch is None else emb[batch]\n",
    "        \n",
    "        # collate fn이 뭐지?\n",
    "        def loader(self, **kwargs):\n",
    "            return DataLoader( range(self.num_nodes_dict[self.metapath[0][0]]),\n",
    "                              \n",
    "            )\n",
    "        \n",
    "        \n",
    "        # \n",
    "        def pos_sample(self, batch):\n",
    "            \n",
    "            batch = batch.repeat(self.walks_per_node)\n",
    "            \n",
    "            rws = [batch]\n",
    "            for i in range(self.walk_length):\n",
    "                keys = self.metapath[i % len(self.metapath)]\n",
    "        \n",
    "        \n",
    "        # batch의 type을 Tensor로 바꿔줌\n",
    "        def sample(self, batch):\n",
    "            if not isinstance(batch, torch.Tensor):\n",
    "                batch = torch.tensor(batch)\n",
    "            return self.pos_sample(batch), self.neg_sample(batch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # \n",
    "        def loss(self, pos_rw, neg_rw):\n",
    "            \"\"\"\n",
    "            Computes the loss given positive and negative random walks\n",
    "            \"\"\"\n",
    "            \n",
    "            # Positive loss\n",
    "            start ,rest = pos_rw[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 1, 2, 3])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.repeat(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('author', 'wrote', 'paper'),\n",
       " ('paper', 'published in', 'venue'),\n",
       " ('venue', 'published', 'paper'),\n",
       " ('paper', 'written by', 'author')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def loader(self, **kwargs):\n",
    "        return DataLoader(range(self.num_nodes_dict[self.metapath[0][0]]),\n",
    "                          collate_fn=self.sample, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0])\n",
      "1 tensor([1])\n",
      "2 tensor([2])\n",
      "3 tensor([3])\n",
      "4 tensor([4])\n"
     ]
    }
   ],
   "source": [
    "for i, a in enumerate(DataLoader(range(5))):\n",
    "    print(i, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "  edge_index_dict={\n",
       "    ('paper', 'written by', 'author')=[2, 9323605],\n",
       "    ('author', 'wrote', 'paper')=[2, 9323605],\n",
       "    ('paper', 'published in', 'venue')=[2, 3194405],\n",
       "    ('venue', 'published', 'paper')=[2, 3194405]\n",
       "  },\n",
       "  num_nodes_dict={\n",
       "    paper=3194405,\n",
       "    author=1693531,\n",
       "    venue=3883\n",
       "  },\n",
       "  y_dict={\n",
       "    author=[246678],\n",
       "    venue=[134]\n",
       "  },\n",
       "  y_index_dict={\n",
       "    author=[246678],\n",
       "    venue=[134]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': tensor([0, 2, 5,  ..., 0, 1, 5]),\n",
       " 'venue': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
       "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374]),\n",
       " 'venue': tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
       "         2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
       "         1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
       "          492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
       "          721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
       "          477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
       "         3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
       "         1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
       "         2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
       "         2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
       "         1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
       "          208,  462])}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_dict['author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 1, 4, 2, 9, 5, 6, 7, 3, 0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_index_dict['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study2",
   "language": "python",
   "name": "study2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
